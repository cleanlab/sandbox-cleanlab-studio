{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Demo\n",
    "Demonstrates reading an Avro dataset + Avro | Parquet Cleanlab Columns, joins them, and saves result to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pyspark.sql\n",
    "import pyspark.sql.functions\n",
    "\n",
    "import sys; sys.path.insert(0, \"../src/\")\n",
    "from random_cleanlab_columns import generate_random_ood_columns, generate_random_cleanlab_columns\n",
    "from sample_data import DATA_DIR, fetch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/28 23:13:16 WARN Utils: Your hostname, Ryans-MacBook-Pro-3.local resolves to a loopback address: 127.0.0.1; using 192.168.0.4 instead (on interface en0)\n",
      "23/02/28 23:13:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/ryansingman/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/ryansingman/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/ryansingman/.ivy2/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e9fa030d-ee83-41fe-8845-8a6467705deb;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.3.2 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      ":: resolution report :: resolve 130ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.spark#spark-avro_2.12;3.3.2 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e9fa030d-ee83-41fe-8845-8a6467705deb\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/28 23:13:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/28 23:13:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/28 23:13:17 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.12:3.3.2 pyspark-shell'\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\n",
    "    \"dataset_view_demo\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset to use\n",
    "DATASET_TO_USE = \"Tweets-1M.csv\"\n",
    "DATASET_PATH = fetch_dataset(DATASET_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+---------------+-------------------+-------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "|            tweet_id|airline_sentiment|airline_sentiment_confidence|negativereason|negativereason_confidence|       airline|airline_sentiment_gold|           name|negativereason_gold|retweet_count|                text|tweet_coord|       tweet_created|      tweet_location|       user_timezone|\n",
      "+--------------------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+---------------+-------------------+-------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "|                   0|          neutral|                         1.0|          null|                     null|Virgin America|                  null|        cairdin|               null|            0|@VirginAmerica Wh...|       null|2015-02-24 11:35:...|                null|Eastern Time (US ...|\n",
      "|                   1|         positive|                      0.3486|          null|                      0.0|Virgin America|                  null|       jnardino|               null|            0|@VirginAmerica pl...|       null|2015-02-24 11:15:...|                null|Pacific Time (US ...|\n",
      "|                   2|          neutral|                      0.6837|          null|                     null|Virgin America|                  null|     yvonnalynn|               null|            0|@VirginAmerica I ...|       null|2015-02-24 11:15:...|           Lets Play|Central Time (US ...|\n",
      "|                   3|         negative|                         1.0|    Bad Flight|                   0.7033|Virgin America|                  null|       jnardino|               null|            0|@VirginAmerica it...|       null|2015-02-24 11:15:...|                null|Pacific Time (US ...|\n",
      "|                   4|         negative|                         1.0|    Can't Tell|                      1.0|Virgin America|                  null|       jnardino|               null|            0|@VirginAmerica an...|       null|2015-02-24 11:14:...|                null|Pacific Time (US ...|\n",
      "|                   5|         negative|                         1.0|    Can't Tell|                   0.6842|Virgin America|                  null|       jnardino|               null|            0|@VirginAmerica se...|       null|                null|                null|                null|\n",
      "|it's really the o...|             null|        2015-02-24 11:14:...|          null|     Pacific Time (US ...|          null|                  null|           null|               null|         null|                null|       null|                null|                null|                null|\n",
      "|                   6|         positive|                      0.6745|          null|                      0.0|Virgin America|                  null|     cjmcginnis|               null|            0|@VirginAmerica ye...|       null|2015-02-24 11:13:...|    San Francisco CA|Pacific Time (US ...|\n",
      "|                   7|          neutral|                       0.634|          null|                     null|Virgin America|                  null|          pilot|               null|            0|@VirginAmerica Re...|       null|2015-02-24 11:12:...|         Los Angeles|Pacific Time (US ...|\n",
      "|                   8|         positive|                      0.6559|          null|                     null|Virgin America|                  null|       dhepburn|               null|            0|@virginamerica We...|       null|2015-02-24 11:11:...|           San Diego|Pacific Time (US ...|\n",
      "|                   9|         positive|                         1.0|          null|                     null|Virgin America|                  null|     YupitsTate|               null|            0|@VirginAmerica it...|       null|2015-02-24 10:53:...|         Los Angeles|Eastern Time (US ...|\n",
      "|                  10|          neutral|                      0.6769|          null|                      0.0|Virgin America|                  null|idk_but_youtube|               null|            0|@VirginAmerica di...|       null|2015-02-24 10:48:...|     1/1 loner squad|Eastern Time (US ...|\n",
      "|                  11|         positive|                         1.0|          null|                     null|Virgin America|                  null|   HyperCamiLax|               null|            0|@VirginAmerica I ...|       null|2015-02-24 10:30:...|                 NYC|    America/New_York|\n",
      "|                  12|         positive|                         1.0|          null|                     null|Virgin America|                  null|   HyperCamiLax|               null|            0|@VirginAmerica Th...|       null|2015-02-24 10:30:...|                 NYC|    America/New_York|\n",
      "|                  13|         positive|                      0.6451|          null|                     null|Virgin America|                  null|   mollanderson|               null|            0|@VirginAmerica @v...|       null|2015-02-24 10:21:...|                null|Eastern Time (US ...|\n",
      "|                  14|         positive|                         1.0|          null|                     null|Virgin America|                  null|       sjespers|               null|            0|@VirginAmerica Th...|       null|2015-02-24 10:15:...|   San Francisco, CA|Pacific Time (US ...|\n",
      "|                  15|         negative|                      0.6842|   Late Flight|                   0.3684|Virgin America|                  null|smartwatermelon|               null|            0|@VirginAmerica SF...|       null|2015-02-24 10:01:...|       palo alto, ca|Pacific Time (US ...|\n",
      "|                  16|         positive|                         1.0|          null|                     null|Virgin America|                  null|  ItzBrianHunty|               null|            0|@VirginAmerica So...|       null|2015-02-24 09:42:...|         west covina|Pacific Time (US ...|\n",
      "|                  17|         negative|                         1.0|    Bad Flight|                      1.0|Virgin America|                  null|  heatherovieda|               null|            0|@VirginAmerica  I...|       null|2015-02-24 09:39:...|this place called...|Eastern Time (US ...|\n",
      "|                  18|         positive|                         1.0|          null|                     null|Virgin America|                  null|   thebrandiray|               null|            0|I ❤️ flying @Virg...|       null|2015-02-24 09:15:...|Somewhere celebra...|Atlantic Time (Ca...|\n",
      "+--------------------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+---------------+-------------------+-------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load dataset to dataframe\n",
    "dataset_df = spark.read.option(\"header\", True).option(\"escape\", '\"').format(\"csv\").load(str(DATASET_PATH))\n",
    "\n",
    "# save dataset to Avro\n",
    "AVRO_DATASET_PATH = DATASET_PATH.with_suffix(\".avro\")\n",
    "dataset_df.write.format(\"avro\").save(str(AVRO_DATASET_PATH), mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Cleanlab columns and save to Avro + Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avro_filename_template = str(AVRO_DATASET_PATH).replace(\".avro\", \"-{filetype}.avro\")\n",
    "\n",
    "def _create_filename(filetype: str, format: str) -> str:\n",
    "    return str(AVRO_DATASET_PATH).replace(\".avro\", f\"-{filetype}.{format}\")\n",
    "\n",
    "def save_df(df_table: pyspark.sql.DataFrame, filetype: str, format: str):\n",
    "    outfile = _create_filename(filetype, format)\n",
    "\n",
    "    df_table.write.format(\"avro\").save(outfile, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                  (0 + 8) / 8][Stage 5:>                  (0 + 0) / 8]\r"
     ]
    }
   ],
   "source": [
    "# load spark table from avro\n",
    "dataset_table = spark.read.format(\"avro\").load(str(AVRO_DATASET_PATH))\n",
    "\n",
    "id_column = \"tweet_id\"\n",
    "label_column = \"airline_sentiment\"\n",
    "\n",
    "# generate randomized cleanlab columns\n",
    "cl_cols = generate_random_cleanlab_columns(dataset_table.alias(\"cl_cols_df\"), id_column=id_column, label_column=label_column)\n",
    "\n",
    "# generate randomized OOD columns\n",
    "ood_cols = generate_random_ood_columns(dataset_table.alias(\"ood_cols_df\"), id_column=id_column)\n",
    "\n",
    "# save to avro and parquet\n",
    "for format in (\"avro\", \"parquet\"):\n",
    "    save_df(cl_cols, \"cl_cols\", format)\n",
    "    save_df(ood_cols, \"ood_cols\", format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c352b5f43b626817a3ee00531d8acb728eb3c04bba5cd7e8d5b5c36e507dff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
